{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1nUYklSZiF1mN0P_huJDlh-OA_-cUvXom",
      "authorship_tag": "ABX9TyO0jDbbX23wX33/Y9iOHonI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polyexplorer/open-llm/blob/main/KG_Builder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Dependencies\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git@72958fcd3c98a7afdc61f953aa58c544ebda2f79\n",
        "# ! pip install optimum\n",
        "# ! pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  # Use cu117 if on CUDA 11.7\n",
        "# ! pip install langchain\n",
        "# ! pip install \"unstructured[pdf]\""
      ],
      "metadata": {
        "id": "9vcMF28LvZRj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nb89iwCiy2Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install helpers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auplPlCYxaog",
        "outputId": "a773ebb2-3d5a-485f-96fe-3d982d4defbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting helpers\n",
            "  Downloading helpers-0.2.0-py3-none-any.whl (2.3 kB)\n",
            "Installing collected packages: helpers\n",
            "Successfully installed helpers-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pv_BNSrZxQ8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "## Input data directory\n",
        "inputdirectory = Path(\"/content/drive/MyDrive/ai_songwriter/literature/pdfs\")\n",
        "## This is where the output csv files will be written\n",
        "outputdirectory = Path(f\"/content/drive/MyDrive/ai_songwriter/literature/graphs\")"
      ],
      "metadata": {
        "id": "2hsjFbDNxif9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dir PDF Loader\n",
        "# loader = PyPDFDirectoryLoader(inputdirectory)\n",
        "## File Loader\n",
        "# loader = PyPDFLoader(\"./data/MedicalDocuments/orf-path_health-n1.pdf\")\n",
        "loader = DirectoryLoader(inputdirectory, show_progress=True)\n",
        "documents = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=150,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "pages = splitter.split_documents(documents)\n",
        "print(\"Number of chunks = \", len(pages))\n",
        "print(pages[3].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV0hDPkKxgv-",
        "outputId": "d1fd6635-0ce4-4795-ce52-ba8c7b279756"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [03:47<00:00, 37.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks =  841\n",
            "Summary....................................................................................................................................................... 86 Chapter 3: The Foundations Scale-Steps and Scales ................................................... 87 Scales and Scale-Steps ................................................................................................................................. 88\n",
            "\n",
            "Heptatonic Scales: The Major Scale, The Three Forms of the Minor Scale............................................ 91\n",
            "\n",
            "Solfége Revisited ........................................................................................................................................ 102\n",
            "\n",
            "Heptatonic Scales: Introduction to Modes .............................................................................................. 106\n",
            "\n",
            "Other Commonly Used Scales ................................................................................................................... 113\n",
            "\n",
            "Summary..................................................................................................................................................... 120 Chapter 4: Key Sense, Key Signatures, and The Cycle of Fifths .............................. 121 The Sense of Key: Attributes..................................................................................................................... 122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "import pandas as pd\n",
        "\n",
        "def documents2Dataframe(documents) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for chunk in documents:\n",
        "        row = {\n",
        "            \"text\": chunk.page_content,\n",
        "            **chunk.metadata,\n",
        "            \"chunk_id\": uuid.uuid4().hex,\n",
        "        }\n",
        "        rows = rows + [row]\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "\n",
        "df = documents2Dataframe(pages)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "kwykJm510DMl",
        "outputId": "507500a4-acc7-4e1d-dcaa-ef831210b625"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(841, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Music Theory\\n\\nv. 1.0\\n\\nThis is the book Mus...   \n",
              "1  About the Author ................................   \n",
              "2  Summary..........................................   \n",
              "3  Summary..........................................   \n",
              "4  The Cycle of Fifths as a Mnemonic Device ........   \n",
              "\n",
              "                                              source  \\\n",
              "0  /content/drive/MyDrive/ai_songwriter/literatur...   \n",
              "1  /content/drive/MyDrive/ai_songwriter/literatur...   \n",
              "2  /content/drive/MyDrive/ai_songwriter/literatur...   \n",
              "3  /content/drive/MyDrive/ai_songwriter/literatur...   \n",
              "4  /content/drive/MyDrive/ai_songwriter/literatur...   \n",
              "\n",
              "                           chunk_id  \n",
              "0  9435620944ae4747b2b25025a31b9cf9  \n",
              "1  7d8df3f0131d4ca283b45d75196f3880  \n",
              "2  31a7cacca4dd4285b0725d377d0fff71  \n",
              "3  d14a494367b146ea841905d785365ad1  \n",
              "4  1d255581ed954b77a6a45d06029d373b  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df3a5e6d-0b03-4444-91eb-5c884970fdff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>chunk_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Music Theory\\n\\nv. 1.0\\n\\nThis is the book Mus...</td>\n",
              "      <td>/content/drive/MyDrive/ai_songwriter/literatur...</td>\n",
              "      <td>9435620944ae4747b2b25025a31b9cf9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>About the Author ................................</td>\n",
              "      <td>/content/drive/MyDrive/ai_songwriter/literatur...</td>\n",
              "      <td>7d8df3f0131d4ca283b45d75196f3880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Summary..........................................</td>\n",
              "      <td>/content/drive/MyDrive/ai_songwriter/literatur...</td>\n",
              "      <td>31a7cacca4dd4285b0725d377d0fff71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Summary..........................................</td>\n",
              "      <td>/content/drive/MyDrive/ai_songwriter/literatur...</td>\n",
              "      <td>d14a494367b146ea841905d785365ad1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Cycle of Fifths as a Mnemonic Device ........</td>\n",
              "      <td>/content/drive/MyDrive/ai_songwriter/literatur...</td>\n",
              "      <td>1d255581ed954b77a6a45d06029d373b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df3a5e6d-0b03-4444-91eb-5c884970fdff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df3a5e6d-0b03-4444-91eb-5c884970fdff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df3a5e6d-0b03-4444-91eb-5c884970fdff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7c8e165-d1dc-495f-ade2-265b7f42985b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7c8e165-d1dc-495f-ade2-265b7f42985b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7c8e165-d1dc-495f-ade2-265b7f42985b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM"
      ],
      "metadata": {
        "id": "8JMtUJanA0yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mistral Wrapper\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer,GPTQConfig, pipeline,TextStreamer\n",
        "import torch\n",
        "from typing import Any, List, Mapping, Optional\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "\n",
        "class MistralModel:\n",
        "    def __init__(self):\n",
        "        # Refresh CUDA Memory\n",
        "        torch.cuda.empty_cache()\n",
        "        self.model,self.tokenizer = self.get_model()\n",
        "        streamer = TextStreamer(self.tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "        self.pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=self.model,\n",
        "            tokenizer=self.tokenizer,\n",
        "            max_new_tokens=4092,\n",
        "            do_sample=True,\n",
        "            temperature=0.1,\n",
        "            top_k=40,\n",
        "            top_p=0.95,\n",
        "            repetition_penalty=1.15,\n",
        "            streamer=streamer,\n",
        "        )\n",
        "\n",
        "\n",
        "    def format_prompt(self,prompt):\n",
        "        return f\"\"\"<s>[INST] {prompt} [/INST]\"\"\"\n",
        "\n",
        "    def generate_instruction(\n",
        "        self,\n",
        "        prompt:str,\n",
        "        instruction:str = 'Think carefully and answer the given question as truthfully as possible',\n",
        "        llm_template = None\n",
        "    ):\n",
        "        # if not llm_template:\n",
        "        #     llm_template = self.format_prompt\n",
        "        instruction_format = f\"\"\"### Instruction: {instruction}:\n",
        "\n",
        "    ### Input:\n",
        "    {prompt}\n",
        "\n",
        "    ### Response:\n",
        "    \"\"\"\n",
        "        if llm_template:\n",
        "            return llm_template(instruction_format)\n",
        "        else:\n",
        "            return instruction_format\n",
        "\n",
        "\n",
        "    def get_model(self):\n",
        "        # model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\"\n",
        "        model_name_or_path = \"TheBloke/Mistral-7B-OpenOrca-GPTQ\"\n",
        "        # To use a different branch, change revision\n",
        "        # For example: revision=\"main\"\n",
        "        quantization_config_loading = GPTQConfig(bits=4, use_exllama = False)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
        "\n",
        "                                                  quantization_config=quantization_config_loading,\n",
        "                                                  device_map=\"cuda\",\n",
        "                                                  trust_remote_code=True,\n",
        "                                                  revision=\"gptq-4bit-32g-actorder_True\")\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "        return model, tokenizer\n",
        "\n",
        "    def _predict(self, prompt):\n",
        "        torch.cuda.empty_cache()\n",
        "        response =  self.pipe(self.format_prompt(prompt))[0]['generated_text']\n",
        "        return response\n",
        "\n",
        "    def predict(self,prompt):\n",
        "        return self._predict(prompt).split(r'INST]')[-1].strip()\n",
        "\n",
        "    def ask(self,question,instruction = None):\n",
        "        formatted_prompt = self.generate_instruction(prompt=question,instruction=instruction)\n",
        "        return self.predict(formatted_prompt)\n",
        "\n",
        "class MistralLLM(LLM):\n",
        "    mistral_model: MistralModel\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        # if stop is not None:\n",
        "        #     raise ValueError(\"stop kwargs are not permitted.\")\n",
        "        return self.mistral_model.ask(prompt)\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        \"\"\"Get the identifying parameters.\"\"\"\n",
        "        return {\"model\": self.mistral_model}"
      ],
      "metadata": {
        "id": "EsO14mwfA1lS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MistralModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XigYoSa-B0UL",
        "outputId": "ab77cb3f-d199-460c-e841-970a82404e3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. disable_exllama, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = model.ask(\"What is the view of philosophy on giving importance to happiness?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esBYOBzmED_x",
        "outputId": "ec23f740-b292-46a2-90fb-d1e9ab69d0d1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Philosophy has a diverse range of views when it comes to the importance of happiness. Some philosophers, like Epicurus and Aristotle, believed that happiness was the ultimate goal in life and should be pursued above all else. They argued that a happy life involves both physical and mental well-being, as well as engaging in activities that bring pleasure and satisfaction.\n",
            "\n",
            "   Other philosophers, such as Socrates and Plato, focused more on knowledge and virtue than on personal happiness. They believed that true happiness could only be achieved through understanding and living according to moral principles. In their view, seeking happiness for its own sake might lead to selfishness or hedonism, which would ultimately harm society as a whole.\n",
            "\n",
            "   Despite these differing perspectives, many philosophical traditions agree that happiness can be found through a balance between personal fulfillment and contributing positively to one's community. This idea is reflected in various ethical systems, including utilitarianism and virtue ethics, where individuals are encouraged to act in ways that promote the greatest good for the most people.\n",
            "\n",
            "   Ultimately, the view of philosophy on the importance of happiness depends on the specific philosopher or school of thought being considered. However, there is general agreement that happiness is an essential aspect of human flourishing and that it can be achieved through a combination of individual well-being and social responsibility.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbJnvGfREQpt",
        "outputId": "25db18ad-e87f-4f62-946d-dd51971f1f3d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Philosophy has a diverse range of views when it comes to the importance of happiness. Some philosophers, like Epicurus and Aristotle, believed that happiness was the ultimate goal in life and should be pursued above all else. They argued that a happy life involves both physical and mental well-being, as well as engaging in activities that bring pleasure and satisfaction.\n",
            "\n",
            "    Other philosophers, such as Socrates and Plato, focused more on knowledge and virtue than on personal happiness. They believed that true happiness could only be achieved through understanding and living according to moral principles. In their view, seeking happiness for its own sake might lead to selfishness or hedonism, which would ultimately harm society as a whole.\n",
            "\n",
            "    Despite these differing perspectives, many philosophical traditions agree that happiness can be found through a balance between personal fulfillment and contributing positively to one's community. This idea is reflected in various ethical systems, including utilitarianism and virtue ethics, where individuals are encouraged to act in ways that promote the greatest good for the most people.\n",
            "\n",
            "    Ultimately, the view of philosophy on the importance of happiness depends on the specific philosopher or school of thought being considered. However, there is general agreement that happiness is an essential aspect of human flourishing and that it can be achieved through a combination of individual well-being and social responsibility.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[100]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8yqdrd6CQha",
        "outputId": "ef51802a-7bdc-4d5d-ca3a-887d8062b3ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4 Heptatonic Scales: Introduction to Modes\n",
            "\n",
            "107\n",
            "\n",
            "Chapter 3 The Foundations Scale-Steps and Scales\n",
            "\n",
            "by the use of musia ficta: composers routinely altered pitches to achieve the desired result. For example, the “softening” of the fourth scale degree in Lydian, or adding a Leading Tone to Dorian and Mixolydian.Because of its unique character, Phrygian was resistant to any alteration.\n",
            "\n",
            "Figure 3.17 Modes and music ficta\n",
            "\n",
            "Greater Modal System\n",
            "\n",
            "In practical composition, the altered version of the mode became the version used. The resulting mixtures of mode and alteration in time yielded new scales, recognized as such by established practice. This was codified in the Greater Modal System.\n",
            "\n",
            "Figure 3.18 The Greater Modal System (Abbreviated)\n",
            "\n",
            "Audio 12\n",
            "\n",
            "The Modes\n",
            "\n",
            "(click to see video)\n",
            "\n",
            "Note that Ionian is the Major scale and Aeolian is the Natural Minor scale. The other earlier modes (again by established practice) gradually polarized toward one or the other of these two forms. Due to the perceived flaws of each mode, they eroded under the weight of their own inefficiency and distilled into either the “Major” mode, or the “Minor” mode. The Locrian mode, while recognized as a theoretical mode was not used in practical composition due to its unstable final resolution.Locrian was not included in the system of modes until 1482 where it was\n",
            "\n",
            "3.4 Heptatonic Scales: Introduction to Modes\n",
            "\n",
            "108\n",
            "\n",
            "Chapter 3 The Foundations Scale-Steps and Scales\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \\\n",
        "\"\"\"\n",
        "You are a good text editor who reconstructs a given context.\n",
        "You are provided a context chunk (delimited by ```). This context is an excerpt from a book/article. Your task is to Edit out unnecassary information (chapter metadata, book info, extra spaces, figures, audio etc)\n",
        "Thought 1: While traversing through each sentence, If it is related to book/article metadata, delete it.\n",
        "Thought 2: Think about the rest of the sentences and see if they have any errors\n",
        "  Errors are Spelling Mistakes, Grammatical Errors\n",
        "  Out of place special characters.\n",
        "  Gibberish words/sentences\n",
        "Thought 3: Create an almost verbatim version of the text (DON'T mention the author/chapters or any meta information) having all information that is present in the context. Fill out details if needed.\n",
        "  Words, phrases that seem incomplete (Sic).\n",
        "\n",
        "Make a clear consice version of the text\n",
        "Remove any reference to the book/author/chapters.\n",
        "\"\"\"\n",
        "\n",
        "question = f\"```{df.iloc[101]['text']}```\"\n",
        "\n",
        "sample_processed = model.ask(question = question, instruction=instruction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV2G2dLBErUs",
        "outputId": "cf922448-7560-42dd-ddfe-4bde7e7a7549"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "   Heptatonic Scales: Introduction to Modes\n",
            "\n",
            "The Associative Method is a technique used for learning modes and understanding their characteristics. It involves classifying modes based on whether they share the same basic qualities as Major or Minor scales, and then identifying the differences between them.\n",
            "\n",
            "Major sounding modes include Ionian, Lydian, Dorian, Mixolydian, and Locrian (with variations). On the other hand, minor sounding modes consist of Aeolian and Phrygian.\n",
            "\n",
            "The Associative Method can be helpful in various situations, particularly when it comes to recognizing and singing modes. Some individuals suggest employing a comparable approach for this purpose.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EizNLsQLHXom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(sample_processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjNawdkRHGrq",
        "outputId": "075b2e65-5131-461a-d62d-2d6331459970"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Heptatonic Scales: Introduction to Modes\\n'\n",
            " '\\n'\n",
            " 'The Associative Method is a technique used for learning modes and '\n",
            " 'understanding their characteristics. It involves classifying modes based on '\n",
            " 'whether they share the same basic qualities as Major or Minor scales, and '\n",
            " 'then identifying the differences between them.\\n'\n",
            " '\\n'\n",
            " 'Major sounding modes include Ionian, Lydian, Dorian, Mixolydian, and Locrian '\n",
            " '(with variations). On the other hand, minor sounding modes consist of '\n",
            " 'Aeolian and Phrygian.\\n'\n",
            " '\\n'\n",
            " 'The Associative Method can be helpful in various situations, particularly '\n",
            " 'when it comes to recognizing and singing modes. Some individuals suggest '\n",
            " 'employing a comparable approach for this purpose.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \\\n",
        "        \"\"\"You are a network graph maker who extracts important terms and their relations from a given Summary.\n",
        "        You are provided with a context chunk (delimited by ```) Your task is to extract the ontology\n",
        "        of terms mentioned in the given context. These terms should represent the key concepts as per the context.\n",
        "        Thought 1: While traversing through each sentence, Think about the key terms mentioned in it.\n",
        "            Terms may include object, entity, location, organization, person,\n",
        "            condition, acronym, documents, service, concept, etc.\n",
        "            Terms should be as atomistic as possible\n",
        "\n",
        "        Thought 2: Think about how these terms can have one on one relation with other terms.\n",
        "            Terms that are mentioned in the same sentence or the same paragraph are typically related to each other.\n",
        "            Terms can be related to many other terms\n",
        "        Thought 3: Find out the relation between each such related pair of terms.\n",
        "        Format your output as a list of json. Each element of the list contains a pair of terms\"\n",
        "        and the relation between them, like the follwing:\n",
        "        [\n",
        "           {\n",
        "               \"node_1\": \"A concept from extracted ontology\",\n",
        "               \"node_2\": \"A related and similar concept from extracted ontology\",\n",
        "               \"edge\": \"relationship between the two concepts, node_1 and node_2 in one or two sentences\",\n",
        "               \"weight\":\"weight of the relationship between 1 and 10\"\n",
        "           }, {...} at leest 5\n",
        "        ]\n",
        "    \"\"\"\n",
        "question = f\"```{sample_processed}```\"\n",
        "sample_concept = model.ask(question = question, instruction=instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMVIwzLACJT9",
        "outputId": "31fa39ef-3581-4fcf-d488-2c327f690640"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "   [\n",
            "      {\n",
            "         \"node_1\": \"Associative Method\",\n",
            "         \"node_2\": \"learning modes\",\n",
            "         \"edge\": \"The Associative Method is a technique used for learning modes and understanding their characteristics.\",\n",
            "         \"weight\": 10\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"classification\",\n",
            "         \"node_2\": \"modes\",\n",
            "         \"edge\": \"It involves classifying modes based on whether they share the same basic qualities as Major or Minor scales, and then identifying the differences between them.\",\n",
            "         \"weight\": 9\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"major sounding modes\",\n",
            "         \"node_2\": \"minor sounding modes\",\n",
            "         \"edge\": \"Major sounding modes include Ionian, Lydian, Dorian, Mixolydian, and Locrian (with variations), while minor sounding modes consist of Aeolian and Phrygian.\",\n",
            "         \"weight\": 8\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"recognition\",\n",
            "         \"node_2\": \"singing modes\",\n",
            "         \"edge\": \"The Associative Method can be helpful in various situations, particularly when it comes to recognizing and singing modes.\",\n",
            "         \"weight\": 7\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"comparable approach\",\n",
            "         \"node_2\": \"purpose\",\n",
            "         \"edge\": \"Some individuals suggest employing a comparable approach for this purpose.\",\n",
            "         \"weight\": 6\n",
            "      }\n",
            "   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "def get_concepts_from_text(text:str,model:MistralModel):\n",
        "  instruction_1 = \\\n",
        "\"\"\"\n",
        "You are a good text editor who reconstructs a given context.\n",
        "You are provided a context chunk (delimited by ```). This context is an excerpt from a book/article. Your task is to Edit out unnecassary information (chapter metadata, book info, extra spaces, figures, audio etc)\n",
        "Thought 1: While traversing through each sentence, If it is related to book/article metadata, delete it.\n",
        "Thought 2: Think about the rest of the sentences and see if they have any errors\n",
        "  Errors are Spelling Mistakes, Grammatical Errors\n",
        "  Out of place special characters.\n",
        "  Gibberish words/sentences\n",
        "Thought 3: Create an almost verbatim version of the text (DON'T mention the author/chapters or any meta information) having all information that is present in the context. Fill out details if needed.\n",
        "  Words, phrases that seem incomplete (Sic).\n",
        "\n",
        "Make a clear consice version of the text\n",
        "Remove any reference to the book/author/chapters.\n",
        "\"\"\"\n",
        "  question = f\"```{text}```\"\n",
        "  text_processed = model.ask(question = question, instruction=instruction_1)\n",
        "  instruction_2 = \\\n",
        "        \"\"\"You are a network graph maker who extracts important terms and their relations from a given Summary.\n",
        "        You are provided with a context chunk (delimited by ```) Your task is to extract the ontology\n",
        "        of terms mentioned in the given context. These terms should represent the key concepts as per the context.\n",
        "        Thought 1: While traversing through each sentence, Think about the key terms mentioned in it.\n",
        "            Terms may include object, entity, location, organization, person,\n",
        "            condition, acronym, documents, service, concept, etc.\n",
        "            Terms should be as atomistic as possible\n",
        "\n",
        "        Thought 2: Think about how these terms can have one on one relation with other terms.\n",
        "            Terms that are mentioned in the same sentence or the same paragraph are typically related to each other.\n",
        "            Terms can be related to many other terms\n",
        "        Thought 3: Find out the relation between each such related pair of terms.\n",
        "        Format your output as a list of json. Each element of the list contains a pair of terms\"\n",
        "        and the relation between them, like the follwing:\n",
        "        [\n",
        "           {\n",
        "               \"node_1\": \"A concept from extracted ontology\",\n",
        "               \"node_2\": \"A related and similar concept from extracted ontology\",\n",
        "               \"edge\": \"relationship between the two concepts, node_1 and node_2 in one or two sentences\",\n",
        "               \"weight\":\"weight of the relationship between 1 and 10\"\n",
        "           }, {...} at leest 5\n",
        "        ]\n",
        "    \"\"\"\n",
        "  question = f\"```{text_processed}```\"\n",
        "  text_concept = model.ask(question = question, instruction=instruction_2)\n",
        "  try:\n",
        "    result = ast.literal_eval(text_concept)\n",
        "  except Exception as e:\n",
        "    print(\"Buggy Output:\",text_concept)\n",
        "    result = None\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "PZ9q7Sd1OgF7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = df.iloc[101]['text']\n",
        "print(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovvl9GuGPbpi",
        "outputId": "d8698729-2d73-4563-b8cf-fd0faf1cf7ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4 Heptatonic Scales: Introduction to Modes\n",
            "\n",
            "108\n",
            "\n",
            "Chapter 3 The Foundations Scale-Steps and Scales\n",
            "\n",
            "described in the treatise de Musica of the Spanish composer and theoretician Bartolomé Ramos de Pareja.\n",
            "\n",
            "Associative Method\n",
            "\n",
            "This sense of polarization toward either Major or Minor becomes one useful technique for learning modes and familiarization with their characteristics. The Associative Method22 classifies modes as having the same basic characteristics as either Major or Minor and then recognizes the variances.\n",
            "\n",
            "Major Sounding Modes\n",
            "\n",
            "Minor Sounding Modes\n",
            "\n",
            "Ionian: Major\n",
            "\n",
            "Aeolian: Natural Minor\n",
            "\n",
            "Lydian: Major, raised 4\n",
            "\n",
            "Dorian: Minor, raised 6\n",
            "\n",
            "Mixolydian: Major, lowered 7 Phrygian: Minor, lowered 2\n",
            "\n",
            "Locrian: Minor, lowered 2 & 5\n",
            "\n",
            "(or Locrian: Phrygian, lowered 5)\n",
            "\n",
            "Figure 3.19 The Associative Method for Modes\n",
            "\n",
            "Audio 13\n",
            "\n",
            "Associative Modes\n",
            "\n",
            "22. Recognition of modes by association with either the Major or the Minor scale and observing the variances from these.\n",
            "\n",
            "(click to see video)\n",
            "\n",
            "This method is extremely useful in many instances, especially for recognition purposes and as a tool for learning to hear and sing modes.Some advocate a similar\n",
            "\n",
            "3.4 Heptatonic Scales: Introduction to Modes\n",
            "\n",
            "109\n",
            "\n",
            "Chapter 3 The Foundations Scale-Steps and Scales\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concepts = get_concepts_from_text(sample_text,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHcYgUeeCgMF",
        "outputId": "d34e3297-89c1-4e0d-d08f-bc1844549a33"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "   Heptatonic Scales: Introduction to Modes\n",
            "\n",
            "The Associative Method is a useful technique for learning modes and familiarizing oneself with their characteristics. It involves classifying modes based on whether they share the same fundamental traits as Major or Minor scales, while also identifying differences between them.\n",
            "\n",
            "In Major sounding modes, Ionian has a major quality, Aeolian is natural minor, Lydian features a raised 4, Dorian has a raised 6, Mixolydian has a lowered 7, and Phrygian has a lowered 2. For minor sounding modes, Aeolian is natural minor, Dorian has a minor quality with a raised 6, Lydian has a major quality with a raised 4, Mixolydian has a lowered 7, and Phrygian has a lowered 2 and 5.\n",
            "\n",
            "The Associative Method can be visually represented in Figure 3.19. This approach proves beneficial for mode recognition and learning to hear and sing various modes. Some individuals suggest employing a comparable strategy for recognizing heptatonic scales.\n",
            "\n",
            "\n",
            "   [\n",
            "      {\n",
            "         \"node_1\": \"Associative Method\",\n",
            "         \"node_2\": \"learning modes\",\n",
            "         \"edge\": \"The Associative Method is a useful technique for learning modes and familiarizing oneself with their characteristics.\",\n",
            "         \"weight\": 8\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"Major\",\n",
            "         \"node_2\": \"minor\",\n",
            "         \"edge\": \"Modes are classified based on whether they share the same fundamental traits as Major or Minor scales.\",\n",
            "         \"weight\": 7\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"Ionian\",\n",
            "         \"node_2\": \"major quality\",\n",
            "         \"edge\": \"Ionian has a major quality.\",\n",
            "         \"weight\": 6\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"Aeolian\",\n",
            "         \"node_2\": \"natural minor\",\n",
            "         \"edge\": \"Aeolian is natural minor.\",\n",
            "         \"weight\": 6\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"Lydian\",\n",
            "         \"node_2\": \"raised 4\",\n",
            "         \"edge\": \"Lydian features a raised 4.\",\n",
            "         \"weight\": 6\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"Dorian\",\n",
            "         \"node_2\": \"raised 6\",\n",
            "         \"edge\": \"Dorian has a raised 6.\",\n",
            "         \"weight\": 6\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"Mixolydian\",\n",
            "         \"node_2\": \"lowered 7\",\n",
            "         \"edge\": \"Mixolydian has a lowered 7.\",\n",
            "         \"weight\": 6\n",
            "      },\n",
            "      {\n",
            "         \"node_1\": \"Phrygian\",\n",
            "         \"node_2\": \"lowered 2 and 5\",\n",
            "         \"edge\": \"Phrygian has a lowered 2 and 5.\",\n",
            "         \"weight\": 6\n",
            "      }\n",
            "   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(concepts))\n",
        "print(\"Concepts:\",concepts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD45ZAtsPuUm",
        "outputId": "af1fc09b-2f39-4eda-b65a-84d0f19568c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Concepts: [{'node_1': 'Associative Method', 'node_2': 'learning modes', 'edge': 'The Associative Method is a useful technique for learning modes and familiarizing oneself with their characteristics.', 'weight': 8}, {'node_1': 'Major', 'node_2': 'minor', 'edge': 'Modes are classified based on whether they share the same fundamental traits as Major or Minor scales.', 'weight': 7}, {'node_1': 'Ionian', 'node_2': 'major quality', 'edge': 'Ionian has a major quality.', 'weight': 6}, {'node_1': 'Aeolian', 'node_2': 'natural minor', 'edge': 'Aeolian is natural minor.', 'weight': 6}, {'node_1': 'Lydian', 'node_2': 'raised 4', 'edge': 'Lydian features a raised 4.', 'weight': 6}, {'node_1': 'Dorian', 'node_2': 'raised 6', 'edge': 'Dorian has a raised 6.', 'weight': 6}, {'node_1': 'Mixolydian', 'node_2': 'lowered 7', 'edge': 'Mixolydian has a lowered 7.', 'weight': 6}, {'node_1': 'Phrygian', 'node_2': 'lowered 2 and 5', 'edge': 'Phrygian has a lowered 2 and 5.', 'weight': 6}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = df.head(30)"
      ],
      "metadata": {
        "id": "J0cPhqu4QTeO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgQiLhy2Qf-x",
        "outputId": "1ad419d3-c3b7-487c-8c7e-70bc8b7ac977"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'source', 'chunk_id'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _df_concepts(row):\n",
        "  row['concepts'] = get_concepts_from_text(row['text'], model)\n",
        "  with open('logs.txt','a+') as f:\n",
        "    f.write(row['concepts'])\n",
        "  return row\n",
        "sample_df = sample_df.apply(lambda row: _df_concepts(row), axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MbSiBv0V_0sd",
        "outputId": "5623a232-cf5a-46f7-b799-5386e9969c6d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"node_1\":[INST] ### Instruction: \n",
            "You are a good text editor who reconstructs a given context. \n",
            "You are provided a context chunk (delimited by ```). This context is an excerpt from a book/article. Your task is to Edit out unnecassary information (chapter metadata, book info, extra spaces, figures, audio etc)\n",
            "Thought 1: While traversing through each sentence, If it is related to book/article metadata, delete it. \n",
            "Thought 2: Think about the rest of the sentences and see if they have any errors\n",
            "  Errors are Spelling Mistakes, Grammatical Errors\n",
            "  Out of place special characters.\n",
            "  Gibberish words/sentences\n",
            "Thought 3: Create an almost verbatim version of the text (DON'T mention the author/chapters or any meta information) having all information that is present in the context. Fill out details if needed.\n",
            "  Words, phrases that seem incomplete (Sic).\n",
            "\n",
            "Make a clear consice version of the text\n",
            "Remove any reference to the book/author/chapters.\n",
            ":\n",
            "\n",
            "    ### Input:\n",
            "    ```Music Theory\n",
            "\n",
            "v. 1.0\n",
            "\n",
            "This is the book Music Theory (v. 1.0).\n",
            "\n",
            "This book is licensed under a Creative Commons by-nc-sa 3.0 (http://creativecommons.org/licenses/by-nc-sa/ 3.0/) license. See the license for more details, but that basically means you can share this book as long as you credit the author (but see below), don't make money from it, and do make it available to everyone else under the same terms.\n",
            "\n",
            "This book was accessible as of December 29, 2012, and it was downloaded then by Andy Schmitz (http://lardbucket.org) in an effort to preserve the availability of this book.\n",
            "\n",
            "Normally, the author and publisher would be credited here. However, the publisher has asked for the customary Creative Commons attribution to the original publisher, authors, title, and book URI to be removed. Additionally, per the publisher's request, their name has been removed in some passages. More information is available on this project's attribution page (http://2012books.lardbucket.org/attribution.html?utm_source=header).\n",
            "\n",
            "For more information on the source of this book, or why it is available for free, please see the project's home page (http://2012books.lardbucket.org/). You can browse or download additional books there.\n",
            "\n",
            "ii\n",
            "\n",
            "Table of Contents\n",
            "\n",
            "About the Author .................................................................................................................. 1```\n",
            "\n",
            "    ### Response:\n",
            "     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/INST]\n",
            "\n",
            "   Music Theory\n",
            "\n",
            "   This book is licensed under a Creative Commons by-nc-sa 3.0 license. See the license for more details, but that basically means you can share this book as long as you credit the author (but "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-aab2abd4b97f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concepts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msample_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_df_concepts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-aab2abd4b97f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concepts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msample_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_df_concepts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-aab2abd4b97f>\u001b[0m in \u001b[0;36m_df_concepts\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_df_concepts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concepts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_concepts_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concepts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-5c875a095a0a>\u001b[0m in \u001b[0;36mget_concepts_from_text\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n\u001b[1;32m     18\u001b[0m   \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"```{text}```\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mtext_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstruction_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0minstruction_2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"You are a network graph maker who extracts important terms and their relations from a given Summary. \n",
            "\u001b[0;32m<ipython-input-5-2dbe03c6797e>\u001b[0m in \u001b[0;36mask\u001b[0;34m(self, question, instruction)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mformatted_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMistralLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLLM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2dbe03c6797e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'INST]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2dbe03c6797e>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m             )\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m             \u001b[0;31m# pre-process distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2747\u001b[0m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2748\u001b[0;31m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_warper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2750\u001b[0m             \u001b[0;31m# Store scores, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mfunction_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3253\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3254\u001b[0;31m     return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n\u001b[0m\u001b[1;32m   3255\u001b[0m                                    globals=globals, locals=locals, eval_str=eval_str)\n\u001b[1;32m   3256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3000\u001b[0m                       follow_wrapped=True, globals=None, locals=None, eval_str=False):\n\u001b[1;32m   3001\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3002\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   3003\u001b[0m                                         \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2399\u001b[0m         \u001b[0;31m# In this case we skip the first parameter of the underlying\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m         \u001b[0;31m# function (usually `self` or `cls`).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2401\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_signature_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2461\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2462\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2463\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2464\u001b[0m                                         \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \u001b[0mis_duck_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_functionlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m             \u001b[0mis_duck_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36misfunction\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0m__annotations__\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         __kwdefaults__  dict of keyword only parameters with defaults\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_has_code_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Pow3Z1jvA6K"
      },
      "outputs": [],
      "source": []
    }
  ]
}