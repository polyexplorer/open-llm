{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bpw9cfg2415x",
        "q0xq43o56XIc",
        "fehUYyDm6Aex"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNGMY7dq57xWDBZjuE2Cl9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polyexplorer/open-llm/blob/main/RAG%2BEval(Llama_Index).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "bpw9cfg2415x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Urg3p_p0zZ2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef6dd9d-42b2-4671-ce30-1a90cc39d6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.15.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.346)\n",
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.9.12)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: trulens-eval in /usr/local/lib/python3.10/dist-packages (0.18.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.12)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.1.0+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (2.15.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.10)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.69)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.12.2)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.25.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.8.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: cohere>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (4.37)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (1.0.0)\n",
            "Requirement already satisfied: kaggle>=1.5.13 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (1.5.16)\n",
            "Requirement already satisfied: html2text>=2020.1.16 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (2020.1.16)\n",
            "Requirement already satisfied: merkle-json>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (1.0.0)\n",
            "Requirement already satisfied: millify>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (0.1.1)\n",
            "Requirement already satisfied: pinecone-client>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (2.2.4)\n",
            "Requirement already satisfied: humanize>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (4.7.0)\n",
            "Requirement already satisfied: slack-bolt>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (1.18.1)\n",
            "Requirement already satisfied: slack-sdk>=3.21.3 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (3.26.1)\n",
            "Requirement already satisfied: streamlit>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (1.29.0)\n",
            "Requirement already satisfied: streamlit-aggrid>=0.3.4.post3 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (0.3.4.post3)\n",
            "Requirement already satisfied: streamlit-extras>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (0.3.5)\n",
            "Requirement already satisfied: streamlit-javascript>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (0.1.5)\n",
            "Requirement already satisfied: frozendict>=2.3.8 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (2.3.10)\n",
            "Requirement already satisfied: munch>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (4.0.0)\n",
            "Requirement already satisfied: ipywidgets>=8.0.6 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (8.1.1)\n",
            "Requirement already satisfied: alembic>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from trulens-eval) (1.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.11.2->trulens-eval) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama_index) (2.5)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere>=4.4.1->trulens-eval) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere>=4.4.1->trulens-eval) (1.9.0)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere>=4.4.1->trulens-eval) (6.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere>=4.4.1->trulens-eval) (1.26.18)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.15)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama_index) (1.14.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama_index) (0.14.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.6->trulens-eval) (0.2.0)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.6->trulens-eval) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.6->trulens-eval) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.6->trulens-eval) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.6->trulens-eval) (3.0.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.5.13->trulens-eval) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.5.13->trulens-eval) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.5.13->trulens-eval) (8.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.5.13->trulens-eval) (6.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama_index) (1.7.0)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client>=2.2.1->trulens-eval) (0.7.2)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client>=2.2.1->trulens-eval) (2.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.27.0->trulens-eval) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (5.3.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (3.20.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (13.7.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.27.0->trulens-eval) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2023.3.post1)\n",
            "Requirement already satisfied: python-decouple<4.0,>=3.6 in /usr/local/lib/python3.10/dist-packages (from streamlit-aggrid>=0.3.4.post3->trulens-eval) (3.8)\n",
            "Requirement already satisfied: entrypoints>=0.4 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.4)\n",
            "Requirement already satisfied: htbuilder>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.6.2)\n",
            "Requirement already satisfied: markdownlit>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.0.7)\n",
            "Requirement already satisfied: st-annotated-text>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (4.0.1)\n",
            "Requirement already satisfied: streamlit-camera-input-live>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.2.0)\n",
            "Requirement already satisfied: streamlit-card>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.0.61)\n",
            "Requirement already satisfied: streamlit-embedcode>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.1.2)\n",
            "Requirement already satisfied: streamlit-faker>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.0.3)\n",
            "Requirement already satisfied: streamlit-image-coordinates<0.2.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.1.6)\n",
            "Requirement already satisfied: streamlit-keyup>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (0.2.0)\n",
            "Requirement already satisfied: streamlit-toggle-switch>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (1.0.2)\n",
            "Requirement already satisfied: streamlit-vertical-slider>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens-eval) (1.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (2.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.27.0->trulens-eval) (4.0.11)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from htbuilder>=0.6.2->streamlit-extras>=0.2.7->trulens-eval) (10.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere>=4.4.1->trulens-eval) (3.17.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (4.9.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval) (3.5.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval) (4.9.3)\n",
            "Requirement already satisfied: favicon in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval) (0.7.0)\n",
            "Requirement already satisfied: pymdown-extensions in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval) (10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval) (3.0.0)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval) (20.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval) (3.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.5.13->trulens-eval) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.5.13->trulens-eval) (1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.27.0->trulens-eval) (5.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (0.8.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval) (0.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.6->trulens-eval) (0.2.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval) (3.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu118/\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.5.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.25.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.6)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.1.0+cu118)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.1)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.35.2)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.15.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.1)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.23.7)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.18)\n",
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.7 in /usr/local/lib/python3.10/dist-packages (from pymupdf) (1.23.7)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.13)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.104.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.24.0.post1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.8.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.3)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.59.3)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (28.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.6.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.8.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.19.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "mkdir: cannot create directory ‘pdfs’: File exists\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers optimum accelerate langchain llama_index sentence_transformers peft trulens-eval\n",
        "! pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  # Use cu117 if on CUDA 11.7\n",
        "! pip install pypdf pymupdf chromadb InstructorEmbedding\n",
        "! mkdir pdfs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface LLM (Integrated with LlamaIndex)"
      ],
      "metadata": {
        "id": "YiBHDiDX45Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from transformers import TextStreamer, pipeline\n",
        "import torch\n",
        "\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "model_name_or_path = \"TheBloke/zephyr-7B-beta-GPTQ\"\n",
        "# To use a different branch, change revision\n",
        "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
        "                                             device_map=\"auto\",\n",
        "                                            #  trust_remote_code=False,\n",
        "                                             revision=\"main\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "def generate_response(prompt):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=256,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    response_ids = outputs[0]\n",
        "    response_text = tokenizer.decode(response_ids, skip_special_tokens=True)\n",
        "    return response_text\n",
        "\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=200,\n",
        "            do_sample=True,\n",
        "            temperature=0.1,\n",
        "            top_k=40,\n",
        "            top_p=0.95,\n",
        "            repetition_penalty=1.15,\n",
        "            # streamer=streamer,\n",
        "        )\n",
        "\n",
        "# langchain_llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "system_prompt = \"You are a good Q/A chatbot who always answers the question based on the context only.</s>\"\n",
        "\n",
        "prompt_template = \"\"\"<|user|>\n",
        "{query_str}</s>\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "# prompt_template = \"GPT4 Correct User: {query_str}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    context_window = 4096,\n",
        "    max_new_tokens = 256,\n",
        "    query_wrapper_prompt = prompt_template,\n",
        "    system_prompt = \"\",\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR15JBGn40tg",
        "outputId": "ea04b9bd-0649-4779-96c5-398dc2543f3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6QyGwgDeXvq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic RAG Pipeline"
      ],
      "metadata": {
        "id": "DRLPfRM74mWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ingestion"
      ],
      "metadata": {
        "id": "uO2OAgG358gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Upload"
      ],
      "metadata": {
        "id": "q0xq43o56XIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn, content in uploaded.items():\n",
        "  filename = os.path.join(\"pdfs\",fn)\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "Vng671mr6a9J",
        "outputId": "d7aa0119-05b0-4f4a-9c40-bfe7a6d87070"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2099f0c1-004e-4906-8672-b57c4367101a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2099f0c1-004e-4906-8672-b57c4367101a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DocumentStore"
      ],
      "metadata": {
        "id": "_NI4rK6K5r83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import Document,SimpleDirectoryReader\n",
        "import os\n",
        "# filename = \"/content/pdfs/263-102-00006_Protocol_Amendment_1_14Nov2019.pdf\"\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[filename]\n",
        ").load_data()\n",
        "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
      ],
      "metadata": {
        "id": "QWMIhoA84skW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings"
      ],
      "metadata": {
        "id": "fehUYyDm6Aex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VectorStore Embeddings\n",
        "from llama_index.embeddings import InstructorEmbedding\n",
        "from llama_index import ServiceContext\n",
        "\n",
        "# model_name = \"AnnaWegmann/Style-Embedding\"\n",
        "model_name = \"hkunlp/instructor-large\"\n",
        "text_instruction = \"Represent the Medical document for retrieving important points where answer can be found:\"\n",
        "query_instruction = \"Represent the Medical question for retrieving supporting documents:\"\n",
        "\n",
        "embed_model = InstructorEmbedding(\n",
        "    model_name= model_name,\n",
        "    text_instruction=text_instruction,\n",
        "    query_instruction=query_instruction\n",
        "    )\n",
        "\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm, embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gl-_XQH4shc",
        "outputId": "5c96437c-d56b-4ca3-8963-6871d50d869d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Index"
      ],
      "metadata": {
        "id": "peGJuM_06E9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r sentence_index\n",
        "! rm -r merging_index"
      ],
      "metadata": {
        "id": "57F_DCH7KrMJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-Merging Index\n",
        "\n",
        "from llama_index.node_parser import HierarchicalNodeParser\n",
        "\n",
        "from llama_index.node_parser import get_leaf_nodes\n",
        "from llama_index import StorageContext\n",
        "from llama_index.retrievers import AutoMergingRetriever\n",
        "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "\n",
        "\n",
        "def build_automerging_index(\n",
        "    documents,\n",
        "    llm,\n",
        "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
        "    save_dir=\"merging_index\",\n",
        "    chunk_sizes=None,\n",
        "):\n",
        "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
        "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
        "    nodes = node_parser.get_nodes_from_documents(documents)\n",
        "    leaf_nodes = get_leaf_nodes(nodes)\n",
        "    merging_context = ServiceContext.from_defaults(\n",
        "        llm=llm,\n",
        "        embed_model=embed_model,\n",
        "    )\n",
        "    storage_context = StorageContext.from_defaults()\n",
        "    storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "    if not os.path.exists(save_dir):\n",
        "        automerging_index = VectorStoreIndex(\n",
        "            leaf_nodes, storage_context=storage_context, service_context=merging_context\n",
        "        )\n",
        "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
        "    else:\n",
        "        automerging_index = load_index_from_storage(\n",
        "            StorageContext.from_defaults(persist_dir=save_dir),\n",
        "            service_context=merging_context,\n",
        "        )\n",
        "    return automerging_index\n",
        "\n",
        "def get_automerging_query_engine(\n",
        "    automerging_index,\n",
        "    similarity_top_k=12,\n",
        "    rerank_top_n=2,\n",
        "):\n",
        "    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
        "    retriever = AutoMergingRetriever(\n",
        "        base_retriever, automerging_index.storage_context, verbose=True\n",
        "    )\n",
        "    rerank = SentenceTransformerRerank(\n",
        "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
        "    )\n",
        "    auto_merging_engine = automerging_index.as_query_engine(\n",
        "        similarity_top_k=similarity_top_k,\n",
        "        node_postprocessors=[rerank]\n",
        "        )\n",
        "    return auto_merging_engine\n",
        "\n",
        "\n",
        "# Sentence Window Index\n",
        "\n",
        "from llama_index import ServiceContext, VectorStoreIndex, StorageContext\n",
        "from llama_index.node_parser import SentenceWindowNodeParser\n",
        "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
        "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
        "from llama_index import load_index_from_storage\n",
        "import os\n",
        "\n",
        "\n",
        "# index = VectorStoreIndex.from_documents(documents,\n",
        "#                                         service_context=service_context)\n",
        "\n",
        "def build_sentence_window_index(\n",
        "    documents, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
        "):\n",
        "    # create the sentence window node parser w/ default settings\n",
        "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
        "        window_size=2,\n",
        "        window_metadata_key=\"window\",\n",
        "        original_text_metadata_key=\"original_text\",\n",
        "    )\n",
        "    sentence_context = ServiceContext.from_defaults(\n",
        "        llm=llm,\n",
        "        embed_model=embed_model,\n",
        "        node_parser=node_parser,\n",
        "    )\n",
        "    if not os.path.exists(save_dir):\n",
        "        sentence_index = VectorStoreIndex.from_documents(\n",
        "            documents, service_context=sentence_context\n",
        "        )\n",
        "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
        "    else:\n",
        "        sentence_index = load_index_from_storage(\n",
        "            StorageContext.from_defaults(persist_dir=save_dir),\n",
        "            service_context=sentence_context,\n",
        "        )\n",
        "\n",
        "    return sentence_index\n",
        "\n",
        "\n",
        "\n",
        "def get_sentence_window_query_engine(\n",
        "    sentence_index,\n",
        "    similarity_top_k=6,\n",
        "    rerank_top_n=2,\n",
        "):\n",
        "    # define postprocessors\n",
        "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
        "    rerank = SentenceTransformerRerank(\n",
        "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
        "    )\n",
        "\n",
        "    sentence_window_engine = sentence_index.as_query_engine(\n",
        "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
        "    )\n",
        "    return sentence_window_engine\n",
        "\n",
        "\n",
        "sentence_index = build_sentence_window_index(documents=documents,llm=llm, embed_model=embed_model, save_dir=\"sentence_index\")\n",
        "automerging_index = build_automerging_index(\n",
        "    documents=documents,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model,\n",
        "    save_dir=\"merging_index\"\n",
        ")"
      ],
      "metadata": {
        "id": "kqWIVhuqIQUy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retreival"
      ],
      "metadata": {
        "id": "qF17uD5A6JKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intialize RAG Pipeline"
      ],
      "metadata": {
        "id": "KG9ZzviW-3C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_pipeline = get_sentence_window_query_engine(sentence_index)"
      ],
      "metadata": {
        "id": "AEbpG4whzpPt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_merging_pipeline = get_automerging_query_engine(automerging_index,)\n"
      ],
      "metadata": {
        "id": "sx8L0269PQXP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q/A"
      ],
      "metadata": {
        "id": "PCoLwcSOyxc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_sentence = sentence_pipeline.query(\"Does the study title mention that it is about monitoring Drug-Drug Interactions? Drug drug Interactions occur when two or more drugs interact with each other in a way that affects their effectiveness or safety It is sometimes abbreviated as DDI.  \")\n",
        "print(str(response_sentence), \"\\n-----------------------------------\\n\")\n",
        "\n",
        "response_automerging = auto_merging_pipeline.query(\"Does the study title mention that it is about monitoring Drug-Drug Interactions? Drug drug Interactions occur when two or more drugs interact with each other in a way that affects their effectiveness or safety It is sometimes abbreviated as DDI.  \")\n",
        "print(str(response_automerging))"
      ],
      "metadata": {
        "id": "iFsQpEfA--aR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81840537-26dd-4feb-fa74-0abbd404f4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No, the study title does not mention monitoring Drug-Drug Interactions. The study aims to determine the absorption, metabolism, and excretion of OPC-61815 and characterize its metabolites in healthy male Japanese subjects following a single intravenous dose. The study's objective is to evaluate the likelihood of effects of renal or hepatic impairment on the disposition of OPC-61815 and the likelihood for drug-drug interactions with OPC-61815. However, the study does not explicitly state that it is about monitoring \n",
            "-----------------------------------\n",
            "\n",
            "No, the study title does not mention monitoring Drug-Drug Interactions. The study seems to be focused on evaluating the safety and pharmacokinetics of OPC-61815, a potential treatment for patients with advanced solid tumors, in a Phase I clinical trial. The context information provided does not indicate that the study is specifically designed to monitor Drug-Drug Interactions. However, the study does mention the need to evaluate the likelihood of drug-drug interactions with OPC-61815, which suggests that the study may be monitoring for potential interactions between OPC-61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_2 = sentence_pipeline.query(\"How many patients are planned to be taken for the trial?  \")\n",
        "print(str(response_2))"
      ],
      "metadata": {
        "id": "1go4jk-SzxFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a42ba52-0b86-44d9-d08b-3a6daf0cb7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the context information provided, up to a maximum of 10 subjects will be dosed in total for the trial. Therefore, the number of patients planned to be taken for the trial is up to 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_2.source_nodes[0].node.metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNFFoepoRePe",
        "outputId": "ed2e38a1-a7de-49b7-ce49-36b5cf7bdd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'window': 'Protocol 263- 102-00006  \\n28 \\nConfidential - Proprietary Information   Amendment 1 Approval: 1 4 November 2019 5 Trial Population  \\nIt is planned for at least 8  healthy male Japanese subjects to be dosed to ensure that \\n6 subjects complete the IV infusion.  Up to a maximum of 10 subjects will be dosed in \\ntotal.   \\n',\n",
              " 'original_text': 'Protocol 263- 102-00006  \\n28 \\nConfidential - Proprietary Information   Amendment 1 Approval: 1 4 November 2019 5 Trial Population  \\nIt is planned for at least 8  healthy male Japanese subjects to be dosed to ensure that \\n6 subjects complete the IV infusion. ',\n",
              " 'page_label': '28',\n",
              " 'file_name': '263-102-00006_Protocol_Amendment_1_14Nov2019.pdf',\n",
              " 'file_path': '/content/pdfs/263-102-00006_Protocol_Amendment_1_14Nov2019.pdf',\n",
              " 'file_type': 'application/pdf',\n",
              " 'file_size': 895973,\n",
              " 'creation_date': '2023-12-06',\n",
              " 'last_modified_date': '2023-12-06',\n",
              " 'last_accessed_date': '2023-12-06'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_3 = sentence_pipeline.query(\"What is the age of participants mentioned in the text? \")\n",
        "print(str(response_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdg2qDl0NGN_",
        "outputId": "995ac7db-0319-47b7-c285-082b6db3d449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The participants mentioned in the text are healthy male Japanese subjects between the ages of 35 and 55 years old.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_full = sentence_pipeline.query(\"What are the demographics (age, gender, ethnicity etc) of the patients/subjects being taken for the trial?\")\n",
        "print(str(response_full))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M00nGUnrQi62",
        "outputId": "ac318867-a3e9-4fd5-fb46-dafd3c7acc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The demographic information (collection date, year of birth, age, sex, race, ethnicity, and country) of the patients/subjects will be recorded in the eCRF at the screening visit, as stated in section 5.2 of the protocol. Therefore, the specific demographics of the patients/subjects being taken for the trial will be available in the eCRF data. However, the provided context information does not include prior knowledge of the specific demographics of the patients/subjects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_4 = sentence_pipeline.query(\"In an inpatient study, participants are admitted to a study site or are admitted to a clinic. In an inpatient study, the text also might mention subjects checking in and getting discharged. Is it an inpatient study? \")\n",
        "print(str(response_4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nayNjrTiNVn-",
        "outputId": "62cbe779-061c-43ba-9079-d20bfb5bb5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the context information provided, it is unclear whether this is an inpatient study or an outpatient study. The text mentions \"Final Discharge from trial\" and \"residential treatment period,\" which could suggest an inpatient component, but it also mentions \"2 additional 24-hour nonresidential collections\" and \"outpatient visits,\" which could suggest an outpatient component. Without further information, it is not possible to determine whether this is an inpatient or outpatient study.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_5 = sentence_pipeline.query(\"In an outpatient study, participants visit the study site or must visit a clinic or must visit a hospital. In an outpatient study, participants do not stay overnight. Is it an outpatient study?   \")\n",
        "print(str(response_5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8PMipjaNVlE",
        "outputId": "0978034c-8cbf-4843-de61-8da7afe8124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, based on the provided context information, the study described in the query is an outpatient study. The text states that \"Up to 2 additional 24-hour nonresidential collections (urine and feces) for total radioactivity may occur if discharge criteria have not been met by Day 10. Subjects will collect excreta samples at home for the 24-hour period prior to the clinic visit and deliver them to the trial site at the end of the collection interval, within 24 hours.\" This indicates that some participants may need to make additional visits to the study site for non\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "htQv-vKzEJDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Groundedness"
      ],
      "metadata": {
        "id": "M4dTM2I7sMky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval import Feedback, TruLlama\n",
        "from trulens_eval.feedback.provider.hugs import Huggingface\n",
        "\n",
        "huggingface_provider = Huggingface()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=huggingface_provider)\n",
        "\n",
        "def groundedness_measure_with_cot_reasons(source, statement):\n",
        "  prompt_template = \"\"\"<|system|>\n",
        "  You are a INFORMATION OVERLAP classifier providing the overlap of information between a SOURCE and STATEMENT.\n",
        "For every sentence in the statement, please answer with this template:\n",
        "\n",
        "TEMPLATE:\n",
        "Statement Sentence: <Sentence>,\n",
        "Supporting Evidence: <Choose the exact unchanged sentences in the source that can answer the statement, if nothing matches, say NOTHING FOUND>\n",
        "Score: <Output a number between 0-10 where 0 is no information overlap and 10 is all information is overlapping>\n",
        "</s>\n",
        "<|user|>\n",
        "Give me the INFORMATION OVERLAP of this SOURCE and STATEMENT.\n",
        "\n",
        "SOURCE: {source}\n",
        "\n",
        "STATEMENT: {statement}</s>\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "  groundedness_scores = {}\n",
        "  plausible_junk_char_min = 4\n",
        "  if len(statement) > plausible_junk_char_min:\n",
        "    reason = pipe(prompt_template)[0]['generated_text']\n",
        "  i = 0\n",
        "  for line in reason.split('\\n'):\n",
        "    if \"Score\" in line:\n",
        "      groundedness_scores[f\"statement_{i}\"] = re_0_10_rating(line) / 10\n",
        "      i += 1\n",
        "  return groundedness_scores, {\"reason\": reason}\n",
        "\n",
        "\n",
        "groundedness = (\n",
        "    Feedback(groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
        "        .on(TruLlama.select_source_nodes().node.text)\n",
        "        .on_output()\n",
        "        .aggregate(grounded.grounded_statements_aggregator)\n",
        ")"
      ],
      "metadata": {
        "id": "yIJCmWyGEQgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7375571a-d38e-4215-f580-a15b5c90b226"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function groundedness_measure_with_cot_reasons at 0x7b5e7942f400> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function groundedness_measure_with_cot_reasons at 0x7b5e7942f400> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function groundedness_measure_with_cot_reasons at 0x7b5e7942f400> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function groundedness_measure_with_cot_reasons at 0x7b5e7942f400> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
            "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QS Relevance With CoT reasons (Open Source Implementation)"
      ],
      "metadata": {
        "id": "E3d-fKfLsOPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pat_0_10 = re.compile(r\"\\s*([0-9]+)\\s*$\")\n",
        "\n",
        "\n",
        "def re_0_10_rating(str_val):\n",
        "    matches = pat_0_10.fullmatch(str_val)\n",
        "    if not matches:\n",
        "        # Try soft match\n",
        "        matches = re.search('([0-9]+)(?=\\D*$)', str_val)\n",
        "        if not matches:\n",
        "            print(f\"0-10 rating regex failed to match on: '{str_val}'\")\n",
        "            return -10  # so this will be reported as -1 after division by 10\n",
        "\n",
        "    return int(matches.group())\n",
        "\n",
        "def _extract_score_and_reasons_from_response(\n",
        "    response,\n",
        "    normalize = 10.0\n",
        "):\n",
        "  if \"Supporting Evidence\" in response:\n",
        "    score = 0.0\n",
        "    supporting_evidence = \"\"\n",
        "    for line in response.split('\\n'):\n",
        "      if \"Score\" in line:\n",
        "        score = re_0_10_rating(line) / normalize\n",
        "      if \"Criteria\" in line:\n",
        "        parts = line.split(\":\")\n",
        "        if len(parts) > 1:\n",
        "          criteria = \":\".join(parts[1:]).strip()\n",
        "      if \"Supporting Evidence\" in line:\n",
        "        parts = line.split(\":\")\n",
        "        if len(parts) > 1:\n",
        "          supporting_evidence = \":\".join(parts[1:]).strip()\n",
        "    reasons = {\n",
        "      'reason':\n",
        "          (\n",
        "            f\"{'Criteria: ' + str(criteria) + ' ' if criteria else ''}\\n\"\n",
        "            f\"{'Supporting Evidence: ' + str(supporting_evidence) if supporting_evidence else ''}\"\n",
        "          )\n",
        "    }\n",
        "    return score, reasons\n",
        "  else:\n",
        "    return re_0_10_rating(response) / normalize\n",
        "\n",
        "\n",
        "\n",
        "def relevance_with_cot_reasons(prompt, response):\n",
        "\n",
        "  final_prompt = f\"\"\"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\n",
        "Respond only as a number from 0 to 10 where 0 is the least relevant and 10 is the most relevant.\n",
        "\n",
        "Please answer with this template:\n",
        "\n",
        "TEMPLATE FORMAT:\n",
        "Criteria: <The criteria for your evaluation>\n",
        "Supporting Evidence: <Your reasons for your scoring.>\n",
        "Score: <The score 0-10 based on the given criteria>\n",
        "\n",
        "A few additional scoring guidelines:\n",
        "\n",
        "- Long RESPONSES should score equally well as short RESPONSES.\n",
        "\n",
        "- Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the most RELEVANT.\n",
        "\n",
        "- RESPONSE must be relevant to the entire PROMPT to get a score of 10.\n",
        "\n",
        "- RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\n",
        "\n",
        "- RESPONSE that is RELEVANT to none of the PROMPT should get a score of 0.\n",
        "\n",
        "- RESPONSE that is RELEVANT to some of the PROMPT should get as score of 2, 3, or 4. Higher score indicates more RELEVANCE.\n",
        "\n",
        "- RESPONSE that is RELEVANT to most of the PROMPT should get a score between a 5, 6, 7 or 8. Higher score indicates more RELEVANCE.\n",
        "\n",
        "- RESPONSE that is RELEVANT to the entire PROMPT should get a score of 9 or 10.\n",
        "\n",
        "- RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 10.\n",
        "\n",
        "- RESPONSE that confidently FALSE should get a score of 0.\n",
        "\n",
        "- RESPONSE that is only seemingly RELEVANT should get a score of 0.\n",
        "\n",
        "PROMPT: {prompt}\n",
        "\n",
        "RESPONSE: {response}\n",
        "  \"\"\"\n",
        "  response = pipe(prompt_template.format(query_str=final_prompt))[0]['generated_text']\n",
        "  return _extract_score_and_reasons_from_response(response)\n"
      ],
      "metadata": {
        "id": "Ce-k6p1Zppe_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize all Evaluation Functions"
      ],
      "metadata": {
        "id": "APEwcAjy5w7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from trulens_eval import (\n",
        "    Feedback,\n",
        "    TruLlama\n",
        ")\n",
        "\n",
        "qa_relevance = (\n",
        "    Feedback(relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
        "    .on_input_output()\n",
        ")\n",
        "\n",
        "qs_relevance = (\n",
        "    Feedback(relevance_with_cot_reasons, name = \"Context Relevance\")\n",
        "    .on_input()\n",
        "    .on(TruLlama.select_source_nodes().node.text)\n",
        "    .aggregate(np.mean)\n",
        ")\n",
        "feedbacks = [qa_relevance, qs_relevance, groundedness]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3kTTsglpSkn",
        "outputId": "afbf82d6-fe93-4597-a0ef-bf22baa6779b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function relevance_with_cot_reasons at 0x7b5e7942b370> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function relevance_with_cot_reasons at 0x7b5e7942b370> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function relevance_with_cot_reasons at 0x7b5e7942b370> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function relevance_with_cot_reasons at 0x7b5e7942b370> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function relevance_with_cot_reasons at 0x7b5e7942b370> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function relevance_with_cot_reasons at 0x7b5e7942b370> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n",
            "WARNING:trulens_eval.feedback.feedback:Feedback implementation <function relevance_with_cot_reasons at 0x7b5e7942b370> cannot be serialized: Module __main__ is not importable.. This may be ok unless you are using the deferred feedback mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Eval Pipeline"
      ],
      "metadata": {
        "id": "4jx_H8Z56sr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import Tru, TruLlama\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "\n",
        "eval_questions = [\n",
        "\n",
        "\"Study arms, treatment groups and cohorts are used interchangeably. How many number of study arms are mentioned in this text\"\n",
        ",\n",
        "\"\"\"Does this text mention Translational Medicine Research, which is a research approach that aims to 'translate' findings from fundamental research into medical practice and meaningful health outcomes? One of the examples is utilization of Neurocart. \"\"\"\n",
        ",\n",
        "\"\"\"Does this trial involve Psychedelic Research, which is the study of the effects of psychedelic substances, like LSD and psilocybin, on the human brain and mental health? \"\"\"\n",
        ",\n",
        "\"\"\"Does this trial mention Abuse Liability, which refers to the potential of a drug to be misused, leading to addiction or dependence? \"\"\"\n",
        ",\n",
        "\"\"\"Is this a Basket trial, which is a clinical trial design where multiple subgroups (baskets) of patients, usually with different types of cancer, are tested with a single drug based on a common biomarker? \"\"\"\n",
        ",\n",
        "\"\"\"Is this an Umbrella trial, a type of clinical trial that tests the impact of different drugs on different mutations in a single type of disease, usually cancer, in one 'umbrella' study? \"\"\"\n",
        ",\n",
        "\"\"\"Is this trial conducted over Multiple Phases? \"\"\"\n",
        ",\n",
        "\"\"\"Is this trial Placebo-controlled or an open trial? \"\"\"\n",
        ",\n",
        "\"\"\"Is 'First in Human' mentioned in this text, which refers to the first time a new treatment or procedure is tested in humans? It is also sometimes abbreviated as FIH. \"\"\"\n",
        ",\n",
        "\"\"\"Is it an oncology study? \"\"\"\n",
        ",\n",
        "\"\"\"Is 'Single Ascending Dose' mentioned in this text, referring to a phase in clinical trials where the dosage is gradually increased to evaluate the body's reactions? It is sometimes abbreviated as SAD. \"\"\"\n",
        ",\n",
        "\"\"\"Is 'Multiple Ascending Dose' mentioned in this text, which refers to a method in clinical trials where small groups of subjects receive multiple low doses of the drug, which are gradually increased? It is sometimes abbreviated as MAD. \"\"\"\n",
        ",\n",
        "\"\"\"Is 'Thorough QTc' mentioned in this text, referring to a clinical trial design used to assess the impact of a drug on the heart's QT interval, which is a measure of the time between the start of the Q wave and the end of the T wave in the heart's electrical cycle? \"\"\"\n",
        ",\n",
        "\"\"\"Is Hepatic impairment mentioned in this text, indicating a reduced liver function? \"\"\"\n",
        ",\n",
        "\"\"\"Is Renal impairment mentioned in the text, indicating a reduced kidney function? \"\"\"\n",
        ",\n",
        "\"\"\"Is the trial investigating the drug’s bioavailability? Bioavailability represents the extent and rate at which a drug is absorbed. It is sometimes abbreviated as BA. \"\"\"\n",
        ",\n",
        "\"\"\"Is the trial investigating bioequivalence of drugs? Bioequivalence is the similarity in the rate and extent of drug absorption between two drug products, typically a generic and a brand-name drug. It is sometimes abbreviated as BE. \"\"\"\n",
        ",\n",
        "\"\"\"Does the study title mention that it is about monitoring Drug-Drug Interactions? Drug drug Interactions occur when two or more drugs interact with each other in a way that affects their effectiveness or safety It is sometimes abbreviated as DDI.\"\"\"\n",
        ",\n",
        "\"\"\"Is the trial monitoring Drug-Drug Interactions? Drug drug Interactions occur when two or more drugs interact with each other in a way that affects their effectiveness or safety It is sometimes abbreviated as DDI. \"\"\"\n",
        ",\n",
        "\"\"\"Is mass balance being confirmed in the study? Mass Balance involves accounting for the total amount of a drug that enters and exits a biological system. It is sometimes abbreviated as MB. \"\"\"\n",
        ",\n",
        "\"\"\"Is Food effect mentioned in this text? Food effect describes how the presence or absence of food in the stomach can affect the rate and extent to which a drug is absorbed into the bloodstream. It is sometimes abbreviated as FE. \"\"\"\n",
        ",\n",
        "\"\"\"Patients, subjects, and participants are used interchangeably. Other synonyms are Enrollees, study volunteers, research recruits, cohort members, survey respondents. How many patients are planned for study according to the text?  \"\"\"\n",
        ",\n",
        "\"\"\"Patient Availability(Inclusion/Exclusion criteria and competitive landscape) \"\"\"\n",
        ",\n",
        "\"\"\"What is the age of participants mentioned in the text? \"\"\"\n",
        ",\n",
        "\"\"\"Are Healthy adult participants a part of this trial? \"\"\"\n",
        ",\n",
        "\"\"\"Is the study checking for the influence of the therapy on subjects of diverse ethnicities? \"\"\"\n",
        ",\n",
        "\"\"\"Are any ethnicities mentioned in the text? \"\"\"\n",
        ",\n",
        "\"\"\"Is competing trial mentioned in the text? Competing trial investigates a similar or related intervention as the trial in question. \"\"\"\n",
        ",\n",
        "\"\"\"Is it mentioned in the text that the target population is uncommon? \"\"\"\n",
        ",\n",
        "\"\"\"Is the “target is common” mentioned in the text? \"\"\"\n",
        ",\n",
        "\"\"\"Is it a study related to orphan diseases mentioned in the text? Orphan diseases are rare diseases that affect a relatively small number of individuals. \"\"\"\n",
        ",\n",
        "\"\"\"Is it a study related to a disease with a limited number of medications? \"\"\"\n",
        ",\n",
        "\"\"\"Is paediatric population involved in the study? They are sometimes referred to as children or adolescents. \"\"\"\n",
        ",\n",
        "\"\"\"Is molecular screening a criterion to select patients in the study? Molecular screening criteria refers to the specific genetic, molecular, or biomarker-based characteristics used to identify and select patients for participation in a clinical trial. \"\"\"\n",
        ",\n",
        "\"\"\"Does the study involve inclusion criteria of highly selective eligibility?  \"\"\"\n",
        ",\n",
        "\"\"\"Is it an open label enrolment study? It is a study where participants are aware of the treatment they are receiving and can enroll themselves directly into a particular treatment group or study arm without randomization by researchers. \"\"\"\n",
        ",\n",
        "\"\"\"Is it an open label randomization study? It is a study where both the researchers and the participants are aware of the treatment they are receiving. The randomization process is still used to assign participants to different treatment groups, but everyone involved knows which treatment or intervention the participant is receiving. \"\"\"\n",
        ",\n",
        "\"\"\"Is it a double blind randomization clinical study? \"\"\"\n",
        ",\n",
        "\"\"\"How many treatment modalities are mentioned in the text of treatment section? Treatment modalities are various treatment methods used in the study. They could be medication, surgery, physical therapy, Psychological therapy, radiation therapy, Alternative Medicine, Behavioral interventions. \"\"\"\n",
        ",\n",
        "\"\"\"How many total number of drugs are being assessed as Investigational Medicinal Product in this study? \"\"\"\n",
        ",\n",
        "\"\"\"Count the Trues for below questions \"\"\"\n",
        ",\n",
        "\"\"\"Does the study involve behavioral therapy as per the text of treatment section? \"\"\"\n",
        ",\n",
        "\"\"\"Is dose administration mentioned in text of treatment section? Other synonyms of dose administration are IMP administration and study medication. \"\"\"\n",
        ",\n",
        "\"\"\"Is chemotherapy mentioned in text of treatment section? \"\"\"\n",
        ",\n",
        "\"\"\"Is surgery mentioned in text of treatment section? \"\"\"\n",
        ",\n",
        "\"\"\"Is injection mentioned in text of treatment section? \"\"\"\n",
        ",\n",
        "\"\"\"Is infusion mentioned in text of in treatment section? \"\"\"\n",
        ",\n",
        "\"\"\"Is it mentioned in the text of treatment section that no dose adjustments are allowed? \"\"\"\n",
        ",\n",
        "\"\"\"Are there multiple arms SOA tables? \"\"\"\n",
        ",\n",
        "\"\"\"Are there multiple paths SOA tables? \"\"\"\n",
        ",\n",
        "\"\"\"Is chemotherapy a part of the study? \"\"\"\n",
        ",\n",
        "\"\"\"Is biologics a part of the study? Biologics are drugs produced using biological systems such as bacteria, yeast, or mammalian cells. Biologics are also referred to as biological therapeutics or biopharmaceuticals> \"\"\"\n",
        ",\n",
        "\"\"\"Is rescue medication allowed to be used as mentioned in the text of dosing section? Rescue medications are medications that help in managing conditions that involve sudden symptom exacerbations by providing quick relief. Common rescue medications are Epipen, adrenaline, steroids, triptans, antihistamines etc.  \"\"\"\n",
        ",\n",
        "\"\"\"Is the study related to a high risk toxicity profile? \"\"\"\n",
        ",\n",
        "\"\"\"Is it a life threatening study? \"\"\"\n",
        ",\n",
        "\"\"\"Is pharmacist mentioned in the text? \"\"\"\n",
        ",\n",
        "\"\"\"Is clinical pharmacy mentioned in the text? \"\"\"\n",
        ",\n",
        "\"\"\"Is multiple drug formulation mentioned in the text of dosing section? Multiple drug formulation means a medicinal product contains two or more active ingredients, or drugs, in a single dosage form. It is also sometimes referred to as a combination drug or fixed-dose combination (FDC). \"\"\"\n",
        ",\n",
        "\"\"\"What is the treatment period mentioned in the study? \"\"\"\n",
        ",\n",
        "\"\"\"A study can be inpatient, outpatient or a mix of both. In an inpatient study, participants are admitted to a study site. In an outpatient study, participants visit the study site but do not stay overnight. What type of study is this?  \"\"\"\n",
        ",\n",
        "\"\"\"Are the lab samples sent to one central lab or a different location? Lab samples are sometimes referred to as biomarkers, FBR, Fasting Blood referrals or bodily fluid samples. \"\"\"\n",
        ",\n",
        "\"\"\"Do we require complex frozen packaging for shipment of the lab samples? Complex frozen packaging can involve dry ice, liquid nitrogen, refrigeration, freezer boxes, vacuum insulated dry shipper containers, thermoformed packaging, insulated shipping kits or any kind of customized packagings. \"\"\"\n",
        ",\n",
        "\"\"\"Is Data Monitoring Committee mentioned in the text?It is sometimes abbreviated as DMC or IDMC. \"\"\"\n",
        ",\n",
        "\"\"\"Is Cohort Safety Review mentioned in the text? \"\"\"\n",
        ",\n",
        "\"\"\"Is Dose Escalation Review Team a part of the study? They are sometimes referred to as DERT. \"\"\"\n",
        ",\n",
        "\"\"\"Is Data Safety Monitoring Board a part of the study? They are sometimes referred to as DSMB. \"\"\"\n",
        ",\n",
        "\"\"\"Events requiring adjudication refer to specific events that occur during a clinical trial and need an independent and systematic review or evaluation by a panel of experts or an adjudication committee. Does the study mention about any events requiring adjudication? \"\"\"\n",
        ",\n",
        "\"\"\"Is the data collection happening at a lab for this study? \"\"\"\n",
        ",\n",
        "\"\"\"Are Adverse Events of Special Interest mentioned in the study? They are sometimes abbreviated as AESI or AEs of Special Interest. \"\"\"\n",
        ",\n",
        "\"\"\"Alanine aminotransferase is sometimes abbreviated as ALT. Aspartate aminotransferase is sometimes abbreviated as AST. Upper Limit of Normal is sometimes abbreviated as ULN. Is elevation of alanine aminotransferase or aspartate aminotransferase being compared with Upper limit of normal in the study? \"\"\"\n",
        ",\n",
        "\"\"\"Upper Limit of Normal is sometimes abbreviated as ULN. Is total bilirubin level being compared with upper limit of normal in the study? \"\"\"\n",
        ",\n",
        "\"\"\"Are there sections mentioning Interim?  \"\"\"\n",
        ",\n",
        "\"\"\"Are there sections mentioning IA? \"\"\"\n",
        ",\n",
        "\"\"\"How many sites are planned for the study? \"\"\"\n",
        ",\n",
        "\"\"\"How many countries are planned for the study? \"\"\"\n",
        ",\n",
        "\"\"\"Is a Non-USA country involved in the study? \"\"\"\n",
        ",\n",
        "\"\"\"How many protocol amendments were made according to the text? \"\"\"\n",
        ",\n",
        "\"\"\"Are there any country specific amendments made to the protocol? \"\"\"\n",
        "]\n",
        "\n",
        "def get_prebuilt_trulens_recorder(query_engine, feedbacks, app_id):\n",
        "    tru_recorder = TruLlama(\n",
        "        query_engine,\n",
        "        app_id=app_id,\n",
        "        feedbacks=feedbacks\n",
        "        )\n",
        "    return tru_recorder\n",
        "\n",
        "tru_recorder = get_prebuilt_trulens_recorder(sentence_pipeline, feedbacks,\n",
        "                                             app_id=\"Direct Query Engine\")"
      ],
      "metadata": {
        "id": "oq4vc1mKpShz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import Tru\n",
        "tru = Tru()\n",
        "records , feedback = tru.get_records_and_feedback(app_ids = [])"
      ],
      "metadata": {
        "id": "G4eKN0lVKJ5_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "v80EleJxKojA",
        "outputId": "5a8aca78-0ccc-4ede-c10f-06159326e541"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                app_id                                           app_json  \\\n",
              "0  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
              "1  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
              "2  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
              "\n",
              "                                                type  \\\n",
              "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "\n",
              "                                      record_id  \\\n",
              "0  record_hash_8d67ecd687443344f406500c301a2c81   \n",
              "1  record_hash_cfa2c16b55027c7c6f4bec3033070d29   \n",
              "2  record_hash_1f71b1c53f34286454585afca3100538   \n",
              "\n",
              "                                               input  \\\n",
              "0  \"How many number of Site(s) will this trial ta...   \n",
              "1  \"How many patients are planned to be taken for...   \n",
              "2  \"What is the age of participants mentioned in ...   \n",
              "\n",
              "                                              output tags  \\\n",
              "0  \"Based on the provided context information, th...    -   \n",
              "1  \"Up to a maximum of 10 subjects will be dosed ...    -   \n",
              "2  \"The participants mentioned in the text are he...    -   \n",
              "\n",
              "                                         record_json  \\\n",
              "0  {\"record_id\": \"record_hash_8d67ecd687443344f40...   \n",
              "1  {\"record_id\": \"record_hash_cfa2c16b55027c7c6f4...   \n",
              "2  {\"record_id\": \"record_hash_1f71b1c53f342864545...   \n",
              "\n",
              "                                           cost_json  \\\n",
              "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "2  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "\n",
              "                                           perf_json  \\\n",
              "0  {\"start_time\": \"2023-12-06T12:35:34.816441\", \"...   \n",
              "1  {\"start_time\": \"2023-12-06T12:35:42.017344\", \"...   \n",
              "2  {\"start_time\": \"2023-12-06T12:36:03.608728\", \"...   \n",
              "\n",
              "                           ts  Answer Relevance  Context Relevance  \\\n",
              "0  2023-12-06T12:35:41.606703               1.0                1.0   \n",
              "1  2023-12-06T12:36:03.155157               1.0                1.0   \n",
              "2  2023-12-06T12:36:18.033568               1.0                1.0   \n",
              "\n",
              "                              Answer Relevance_calls Groundedness_calls  \\\n",
              "0  [{'args': {'prompt': 'How many number of Site(...                 []   \n",
              "1  [{'args': {'prompt': 'How many patients are pl...                 []   \n",
              "2  [{'args': {'prompt': 'What is the age of parti...                 []   \n",
              "\n",
              "                             Context Relevance_calls  latency  total_tokens  \\\n",
              "0  [{'args': {'prompt': 'How many number of Site(...        6             0   \n",
              "1  [{'args': {'prompt': 'How many patients are pl...       21             0   \n",
              "2  [{'args': {'prompt': 'What is the age of parti...       14             0   \n",
              "\n",
              "   total_cost  \n",
              "0         0.0  \n",
              "1         0.0  \n",
              "2         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4072e643-a34f-42ac-9d4a-4a39457373bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_json</th>\n",
              "      <th>type</th>\n",
              "      <th>record_id</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>tags</th>\n",
              "      <th>record_json</th>\n",
              "      <th>cost_json</th>\n",
              "      <th>perf_json</th>\n",
              "      <th>ts</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance_calls</th>\n",
              "      <th>Groundedness_calls</th>\n",
              "      <th>Context Relevance_calls</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_8d67ecd687443344f406500c301a2c81</td>\n",
              "      <td>\"How many number of Site(s) will this trial ta...</td>\n",
              "      <td>\"Based on the provided context information, th...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_8d67ecd687443344f40...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2023-12-06T12:35:34.816441\", \"...</td>\n",
              "      <td>2023-12-06T12:35:41.606703</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[{'args': {'prompt': 'How many number of Site(...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'args': {'prompt': 'How many number of Site(...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_cfa2c16b55027c7c6f4bec3033070d29</td>\n",
              "      <td>\"How many patients are planned to be taken for...</td>\n",
              "      <td>\"Up to a maximum of 10 subjects will be dosed ...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_cfa2c16b55027c7c6f4...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2023-12-06T12:35:42.017344\", \"...</td>\n",
              "      <td>2023-12-06T12:36:03.155157</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[{'args': {'prompt': 'How many patients are pl...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'args': {'prompt': 'How many patients are pl...</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_1f71b1c53f34286454585afca3100538</td>\n",
              "      <td>\"What is the age of participants mentioned in ...</td>\n",
              "      <td>\"The participants mentioned in the text are he...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_1f71b1c53f342864545...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2023-12-06T12:36:03.608728\", \"...</td>\n",
              "      <td>2023-12-06T12:36:18.033568</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[{'args': {'prompt': 'What is the age of parti...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'args': {'prompt': 'What is the age of parti...</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4072e643-a34f-42ac-9d4a-4a39457373bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4072e643-a34f-42ac-9d4a-4a39457373bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4072e643-a34f-42ac-9d4a-4a39457373bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f4e3b6c-f22e-4900-bacd-b1df7c15bcf8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f4e3b6c-f22e-4900-bacd-b1df7c15bcf8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f4e3b6c-f22e-4900-bacd-b1df7c15bcf8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tru_recorder as recording:\n",
        "    for question in eval_questions:\n",
        "        response = sentence_pipeline.query(question)\n",
        "\n",
        "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
        "records.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF-TThDkpSfT",
        "outputId": "7818a533-0611-4b3a-9d69-a5387e5f7d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-10 rating regex failed to match on: 'Score: N/A (not applicable)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tru.get_leaderboard(app_ids=[])"
      ],
      "metadata": {
        "id": "1qZI3dUSEos-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "d0cab92a-5072-49c7-b47d-dc29e4c61d81"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Context Relevance  Answer Relevance    latency  \\\n",
              "app_id                                                                \n",
              "Direct Query Engine                1.0               1.0  13.666667   \n",
              "\n",
              "                     total_cost  \n",
              "app_id                           \n",
              "Direct Query Engine         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db8d99f1-ab57-48a5-ae84-8e1e92c11411\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Direct Query Engine</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db8d99f1-ab57-48a5-ae84-8e1e92c11411')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db8d99f1-ab57-48a5-ae84-8e1e92c11411 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db8d99f1-ab57-48a5-ae84-8e1e92c11411');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tru.run_dashboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvAZTRyqCCUU",
        "outputId": "b9453700-7e4d-4a79-ca6e-8371c201cb60"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "Config file already exists. Skipping writing process.\n",
            "Credentials file already exists. Skipping writing process.\n",
            "Dashboard already running at path:   Submit this IP Address: 35.223.170.144\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}